/Users/palaitis/Development/piensa/tools/bin/review-epistemic:46: DeprecationWarning: `OpenAIModel` was renamed to `OpenAIChatModel` to clearly distinguish it from `OpenAIResponsesModel` which uses OpenAI's newer Responses API. Use that unless you're using an OpenAI Chat Completions-compatible API, or require a feature that the Responses API doesn't support yet like audio.
  model = OpenAIModel(model_name, provider='openrouter')
Running epistemic reviewer (openai/gpt-5.1)...
- **Sentence**:  
  > "Costa et al. (2014) demonstrated that bilinguals exhibit reduced cognitive biases when making decisions in their second language compared to their native language."

  **Why it overreaches**:  
  States a general property of bilingual decision-making, whereas Costa et al. tested specific tasks, samples, and contexts.

  **Scope-narrowing rewrite**:  
  > "Costa et al. (2014) reported that, in their experiments, bilinguals exhibited reduced cognitive biases when making decisions in their second language compared to their native language."


- **Sentence**:  
  > "The theoretical explanation centers on emotional distance: L2 processing is more effortful and less emotionally resonant than L1 processing, which promotes more deliberative, 'System 2' reasoning (Kahneman, 2011). This reduced emotional engagement dampens the gut reactions that drive many cognitive biases."

  **Why it overreaches**:  
  Presents one explanatory account as established fact and implies specific mechanistic processes (effort, emotional resonance, System 2) that are not directly measured in your work (and are debated in human literature).

  **Scope-narrowing rewrite**:  
  > "A prominent theoretical explanation centers on emotional distance: L2 processing is hypothesized to be more effortful and less emotionally resonant than L1 processing, which may promote more deliberative, 'System 2' reasoning (Kahneman, 2011). Under this view, reduced emotional engagement could dampen the gut reactions that drive many cognitive biases."


- **Sentence**:  
  > "We tested whether language-specific LoRA adapters could operationalize this Foreign Language Effect in LLMs, hypothesizing that matched adapter-prompt pairs (simulating L1) would produce stronger framing effects than mismatched pairs (simulating L2)."

  **Why it overreaches**:  
  "Operationalize this Foreign Language Effect" and "simulating L1/L2" suggests that the adapters truly capture or simulate the human phenomenon, rather than being one particular operational proxy you evaluate.

  **Scope-narrowing rewrite**:  
  > "We tested whether language-specific LoRA adapters could serve as an operational proxy for the Foreign Language Effect in LLMs, hypothesizing that matched adapter-prompt pairs (intended to approximate L1-like conditions) would produce stronger framing effects than mismatched pairs (intended to approximate L2-like conditions)."


- **Sentence**:  
  > "we confirm that Mistral-7B exhibits the classic framing effect: the model prefers the certain option when outcomes are framed as gains and the risky option when framed as losses."

  **Why it overreaches**:  
  "Confirm" and general "prefers" imply a stable, model-wide property across tasks and settings; your evidence is from one task, one temperature, and specific prompts.

  **Scope-narrowing rewrite**:  
  > "we find that, in this Asian Disease setup, Mistral-7B exhibits the classic framing pattern: higher choice rates for the certain option when outcomes are framed as gains and for the risky option when framed as losses."


- **Sentence**:  
  > "The Foreign Language Effect (FLE) refers to systematic changes in judgment and decision-making when individuals reason in a non-native language."

  **Why it overreaches**:  
  Definition is fine, but "systematic changes" reads as universal; the literature documents heterogeneity and boundary conditions (which you mention later).

  **Scope-narrowing rewrite**:  
  > "The Foreign Language Effect (FLE) refers to systematic changes, observed in many studies, in judgment and decision-making when individuals reason in a non-native language."


- **Sentence**:  
  > "Subsequent meta-analyses confirm the presence of the FLE across domains such as risk evaluation and moral judgment, while also documenting substantial heterogeneity in effect size and sensitivity to task design and participant characteristics (Circi et al., 2021; Del Maschio et al., 2022)."

  **Why it overreaches**:  
  "Confirm the presence" suggests conclusiveness; meta-analyses provide evidence with caveats.

  **Scope-narrowing rewrite**:  
  > "Subsequent meta-analyses provide evidence for the presence of the FLE across domains such as risk evaluation and moral judgment, while also documenting substantial heterogeneity in effect size and sensitivity to task design and participant characteristics (Circi et al., 2021; Del Maschio et al., 2022)."


- **Sentence**:  
  > "The dominant explanatory account attributes the FLE to reduced emotional engagement and affective resonance during foreign-language processing, rather than to increased analytical reasoning capacity (Caldwell-Harris, 2015; Pavlenko, 2017)."

  **Why it overreaches**:  
  Reads as a settled explanatory account; these are theoretical interpretations, not unanimous consensus, and you do not test emotion/analysis mechanisms.

  **Scope-narrowing rewrite**:  
  > "A commonly cited explanatory account attributes the FLE to reduced emotional engagement and affective resonance during foreign-language processing, rather than to increased analytical reasoning capacity (Caldwell-Harris, 2015; Pavlenko, 2017)."


- **Sentence**:  
  > "Recent work demonstrates that large language models reproduce a range of classical cognitive biases when evaluated using established behavioral paradigms."

  **Why it overreaches**:  
  "Demonstrates" and "a range of classical cognitive biases" sounds broad and general; existing work covers specific models, tasks, and prompting regimes.

  **Scope-narrowing rewrite**:  
  > "Recent work reports that, under specific prompting and evaluation setups, large language models can reproduce patterns consistent with several classical cognitive biases when evaluated using established behavioral paradigms."


- **Sentence**:  
  > "These studies indicate that multilingual models often rely on internal normalization or translation mechanisms rather than maintaining fully independent language-specific reasoning pathways."

  **Why it overreaches**:  
  Makes a strong claim about internal mechanisms ("rely on", "rather than maintaining fully independent pathways") that are inferred, not directly observed, and may not generalize across architectures.

  **Scope-narrowing rewrite**:  
  > "These studies have been interpreted as suggesting that multilingual models may rely on internal normalization or translation-like mechanisms, rather than maintaining fully independent language-specific reasoning pathways."


- **Sentence**:  
  > "Modular adapter frameworks demonstrate that separating language adaptation from task adaptation can mitigate some forms of interference, although such separation is not guaranteed in standard language-specific LoRA configurations (Pfeiffer et al., 2020)."

  **Why it overreaches**:  
  "Demonstrate that ... can mitigate" implies a robust, general design principle; the cited work supports this in particular settings.

  **Scope-narrowing rewrite**:  
  > "Modular adapter frameworks provide evidence that, in some settings, separating language adaptation from task adaptation can mitigate certain forms of interference, although such separation is not guaranteed in standard language-specific LoRA configurations (Pfeiffer et al., 2020)."


- **Sentence**:  
  > "Taken together, prior work establishes that framing effects are robust in humans and observable in large language models under controlled conditions, and that multilingual adaptation introduces non-obvious failure modes."

  **Why it overreaches**:  
  "Establishes" and "robust" are strong; your paper does not survey all conditions, and prior LLM work is still emerging.

  **Scope-narrowing rewrite**:  
  > "Taken together, prior work suggests that framing effects are robust in many human experiments and observable in large language models under certain controlled conditions, and that multilingual adaptation can introduce non-obvious failure modes."


- **Sentence**:  
  > "However, no prior study directly tests the Foreign Language Effect in LLMs by operationalizing L1/L2 distinctions via adapter-prompt language alignment, nor treats response validity as a first-class outcome alongside bias magnitude."

  **Why it overreaches**:  
  Absolute literature claim ("no prior study") is hard to defend.

  **Scope-narrowing rewrite**:  
  > "However, to our knowledge, no prior study directly tests the Foreign Language Effect in LLMs by operationalizing L1/L2 distinctions via adapter-prompt language alignment, or treats response validity as a first-class outcome alongside bias magnitude."


- **Sentence**:  
  > "**Empirical evidence against the adapter-based FLE hypothesis**: matched adapter-prompt conditions do not produce stronger framing effects than mismatched conditions."

  **Why it overreaches**:  
  Reads as a general refutation; your evidence is specific to Mistral-7B, your LoRA setup, and this task.

  **Scope-narrowing rewrite**:  
  > "**Empirical evidence against this adapter-based FLE hypothesis in our setup**: in our Mistral-7B experiments, matched adapter-prompt conditions do not produce stronger framing effects than mismatched conditions."


- **Sentence**:  
  > "**Documentation of instruction-following degradation** as a consequence of monolingual LoRA fine-tuning, with implications for multilingual LLM deployment."

  **Why it overreaches**:  
  "As a consequence of" implies causal and general; you show a strong association in one model/configuration, not a universal consequence.

  **Scope-narrowing rewrite**:  
  > "**Documentation of instruction-following degradation** associated with our monolingual LoRA fine-tuning configuration, with potential implications for multilingual LLM deployment."


- **Sentence**:  
  > "All 16 adapter-prompt combinations exhibited positive framing effects in raw choice proportions, confirming that Mistral-7B displays the classic Tversky-Kahneman bias pattern across languages."

  **Why it overreaches**:  
  "Confirming" and "across languages" suggests a stable, global property. Your evidence is limited to one task, specific prompts, and includes conditions with very high unclear rates.

  **Scope-narrowing rewrite**:  
  > "All 16 adapter-prompt combinations exhibited positive framing effects in raw choice proportions, suggesting that, in this task and setup, Mistral-7B displays a Tversky–Kahneman–like framing pattern across the prompt languages tested."


- **Sentence**:  
  > "The pattern suggests that language-specific LoRA training may interfere with the base model's instruction-following capabilities, particularly when there is a mismatch between the adapter's language specialization and the input language."

  **Why it needs minor adjustment**:  
  Good use of "may", but still somewhat general; you only test one base model and specific LoRA parameters.

  **Scope-narrowing rewrite**:  
  > "The pattern suggests that, for Mistral-7B under our LoRA configuration, language-specific adapter training may interfere with the base model's instruction-following capabilities, particularly when there is a mismatch between the adapter's language specialization and the input language."


- **Sentence**:  
  > "All categories reflect failures of instruction adherence rather than ambiguity in choice preference."

  **Why it overreaches**:  
  Asserts that unclear responses are *not* about underlying choice ambiguity; you did not measure latent preferences, only surface form.

  **Scope-narrowing rewrite**:  
  > "All categories are more parsimoniously interpreted as failures of instruction adherence, rather than as clear evidence of ambiguity in choice preference."


- **Sentence**:  
  > "Our experiment was designed to test whether LoRA adapters could simulate L1/L2 processing asymmetries."

  **Why it overreaches**:  
  "Simulate L1/L2 processing asymmetries" sounds like you are approximating human mechanisms; your operationalization is structural (adapter-prompt alignment), not validated as a simulation of human L1/L2 processing.

  **Scope-narrowing rewrite**:  
  > "Our experiment was designed to test whether LoRA adapters could approximate L1/L2-like processing asymmetries via adapter–prompt language alignment."


- **Sentence**:  
  > "Non-English adapters (especially ZH) severely degraded instruction-following. The Chinese adapter produced 96% unclear responses on English prompts. This prevents hypothesis testing for most conditions, but is itself informative: monolingual LoRA fine-tuning can fragment multilingual capabilities."

  **Why it overreaches**:  
  Last clause generalizes from one configuration to monolingual LoRA in general and implies a broad causal statement ("can fragment multilingual capabilities").

  **Scope-narrowing rewrite**:  
  > "Non-English adapters (especially ZH) severely degraded instruction-following. The Chinese adapter produced 96% unclear responses on English prompts. This prevents hypothesis testing for most conditions, but is itself informative: in this model and training configuration, monolingual LoRA fine-tuning appears to fragment multilingual capabilities."


- **Sentence**:  
  > "LoRA modifies capabilities, not processing style. Fine-tuning on Spanish text may make the model better at generating Spanish without creating any asymmetry in cognitive engagement."

  **Why it overreaches**:  
  First sentence is an absolute mechanistic claim about LoRA in general; second invokes "cognitive engagement" in LLMs, which you do not measure.

  **Scope-narrowing rewrite**:  
  > "In our results, LoRA appears to modify surface capabilities (e.g., language fluency) rather than creating the kind of processing-style asymmetries posited in human FLE accounts. Fine-tuning on Spanish text may make the model better at generating Spanish without producing any detectable asymmetry in our framing-task behavior."


- **Sentence**:  
  > "In conditions with low unclear rates (EN adapter across all prompts, HE adapter when matched), the framing effect was robust: P(A|gain) > P(A|loss) in every case."

  **Why it needs minor adjustment**:  
  "Robust" can be read as general or cross-task; your evidence is for this one task and a fixed number of trials per condition.

  **Scope-narrowing rewrite**:  
  > "In conditions with low unclear rates (EN adapter across all prompts, HE adapter when matched), the framing effect consistently appeared in our data: P(A|gain) > P(A|loss) in every such case."


- **Sentence**:  
  > "**What Would Work Better?**"

  **Why it overreaches**:  
  The heading and subsequent text imply that the suggested alternatives *would* outperform your method; you have not tested them.

  **Scope-narrowing rewrite**:  
  > "**Alternative Operationalizations to Explore**"


- **Sentence**:  
  > "We tested whether language-specific LoRA adapters could simulate L1/L2 processing asymmetries in the Asian Disease framing task."

  **Why it overreaches**:  
  Again uses "simulate" as if capturing the human phenomenon; your method is an operational proxy.

  **Scope-narrowing rewrite**:  
  > "We tested whether language-specific LoRA adapters could approximate L1/L2-like processing asymmetries in the Asian Disease framing task."


- **Sentence**:  
  > "The framing effect replicates. Where response data was interpretable, Mistral-7B exhibited the classic Tversky-Kahneman pattern: risk-averse in gain frames, risk-seeking in loss frames."

  **Why it overreaches**:  
  "Replicates" suggests a full replication claim; your replication is partial (one task, one model, specific settings).

  **Scope-narrowing rewrite**:  
  > "The framing effect was observed: where response data were interpretable, Mistral-7B showed the classic Tversky–Kahneman pattern in this task—risk-averse in gain frames and risk-seeking in loss frames."


- **Sentence**:  
  > "Using the Asian Disease framing task, we find that the operationalization of L1/L2 processing tested here—language-specific LoRA adapters evaluated under adapter-prompt language matching—does not reproduce the Foreign Language Effect reported in human studies."

  **Why it needs minor adjustment**:  
  Good overall, but could make explicit that this is for this model and setup, not a blanket statement about the approach.

  **Scope-narrowing rewrite**:  
  > "Using the Asian Disease framing task, we find that, for Mistral-7B under our LoRA configuration, the operationalization of L1/L2 processing tested here—language-specific LoRA adapters evaluated under adapter–prompt language matching—does not reproduce the Foreign Language Effect reported in human studies."


- **Sentence**:  
  > "A secondary finding complicates interpretation: non-English adapters severely degraded instruction-following, producing up to 98% unclear responses. This evaluation failure is distinct from the proxy failure above and must be considered when adapting cognitive decision paradigms to LLMs."

  **Why it overreaches**:  
  Last clause turns your observation into a universal methodological requirement ("must be considered").

  **Scope-narrowing rewrite**:  
  > "A secondary finding complicates interpretation: non-English adapters severely degraded instruction-following, producing up to 98% unclear responses. This evaluation failure is distinct from the proxy failure above and suggests that response validity should be explicitly monitored when adapting cognitive decision paradigms to LLMs."
